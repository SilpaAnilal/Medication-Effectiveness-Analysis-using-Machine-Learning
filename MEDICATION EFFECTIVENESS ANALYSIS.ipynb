{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622e7443",
   "metadata": {},
   "source": [
    "# Medication Effectiveness Analysis: Predicting Hospital Readmission in Diabetes Patients using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538cb69",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbce3bf",
   "metadata": {},
   "source": [
    "Hospital readmission is a critical concern in the healthcare industry, especially for chronic diseases like diabetes, which require consistent monitoring and medication adherence. Unplanned readmissions not only reflect gaps in patient care but also result in increased healthcare costs and patient burden. Among the factors influencing readmission, the effectiveness of prescribed medications plays a crucial role in determining patient outcomes.\n",
    "\n",
    "This project aims to analyze the impact of diabetes medications on the likelihood of hospital readmission. By leveraging a real-world clinical dataset comprising over 100,000 patient records, we investigate how different medication patterns correlate with the chances of a patient being readmitted within 30 days of discharge.\n",
    "\n",
    "The project uses data science and machine learning techniques to build predictive models that classify patients based on their risk of early readmission. The dataset includes patient demographics, hospital visit details, diagnoses, and a variety of diabetes-related medications such as insulin, metformin, glipizide, and others.\n",
    "\n",
    "Through systematic preprocessing, exploratory data analysis, model training, and evaluation, this study not only seeks to predict readmissions but also to highlight which medications or treatment strategies are most associated with improved outcomes. The ultimate goal is to support healthcare professionals in making informed decisions that could reduce readmission rates and improve patient care."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678074ae",
   "metadata": {},
   "source": [
    "#  Aim and Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d89d65",
   "metadata": {},
   "source": [
    "**Aim:** To develop a machine learning model that can accurately predict whether a diabetes patient will be readmitted to the hospital within 30 days, based on the medications prescribed during their hospital stay.\n",
    "\n",
    "**Objective:** To build a binary classification model that predicts hospital readmission (within 30 days or not) using medication data from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d4412",
   "metadata": {},
   "source": [
    "# Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fcd44e",
   "metadata": {},
   "source": [
    "This project focuses on predicting hospital readmission within 30 days for diabetes patients based on medications prescribed during their hospital stay. The analysis is based on the [Diabetes Dataset](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+Hospitals+for+Years+1999-2008), which contains over 100,000 patient records from 130 U.S. hospitals, covering demographics, diagnoses, procedures, and medications.\n",
    "\n",
    "The overall process involves several key steps:\n",
    "\n",
    "**Data Collection:** Publicly available datasets containing medication-related variables and readmission status & Understanding key attributes.\n",
    "\n",
    "**Data preprocessing:** To clean and prepare the dataset for analysis\n",
    "\n",
    "**Exploratory Data Analysis (EDA):** To uncover patterns and relationships between medications and readmissions.\n",
    "\n",
    "**Model Building:** A variety of machine learning models are built, including Logistic Regression, Random Forest, and XGBoost & Decisiontree. Each model is evaluated based on its performance metrics.Tune hyperparameters and assess overfitting.\n",
    "\n",
    "**Model Evaluation:** The best-performing model is selected based on accuracy, precision, recall, F1 score, and Confusion Matrix followed by saving the model for future predictions.\n",
    "\n",
    "**Interpretation and Insights:** Analyzing feature importance to identify which medications most influence readmission & Interpreting results to make meaningful healthcare recommendations.\n",
    "\n",
    "The ultimate goal is to develop a predictive model that helps healthcare providers recognize high-risk patients early, improve treatment strategies, reduce unnecessary hospital readmissions and enhancing patient outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19163b2f",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ce0812",
   "metadata": {},
   "source": [
    "The dataset used in this project is titled [Diabetes Dataset](https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+Hospitals+for+Years+1999-2008), sourced from the **UCI Machine Learning Repository**. It contains medical **records of 101,766 diabetes patient** encounters collected from **130 U.S. hospitals over a 10-year period**. The dataset includes **50 features** that provide a comprehensive view of each hospital visit, covering **patient demographics, hospitalization details, diagnoses, and medication prescriptions**. Key demographic variables include race, gender, and age group, while hospitalization details such as admission type, discharge disposition, admission source, and time spent in the hospital provide insight into each encounter. The dataset also includes medical history indicators such as the number of lab procedures, number of medications, and outpatient or emergency visits. Three diagnosis fields (diag_1, diag_2, diag_3) use ICD-9 codes to classify medical conditions. A **unique aspect** of the dataset is its **inclusion of 22 medication-related columns**, which record the use and dosage changes of common diabetes medications like insulin, metformin, glipizide, and glyburide. Each medication is categorized as No, Steady, Up, or Down, indicating whether the drug was not prescribed, maintained, increased, or decreased during the visit. Additional fields like change and diabetesMed indicate whether there were any changes in medication and whether diabetes-specific medications were prescribed. The **target variable is readmitted**, which shows whether the patient was readmitted to the hospital and when. **It takes three values: <30 (readmitted within 30 days), >30 (readmitted after 30 days), and NO (not readmitted)**. For modeling purposes, this column is converted into a **binary classification variable: 1 for <30 (positive readmission) and 0 for >30 or NO**. Some columns, such as weight and payer_code, contain missing or unknown values marked as '?'. Also, identifiers like encounter_id and patient_nbr are excluded during preprocessing as they do not contribute to the prediction task. Overall, this dataset provides a rich, real-world foundation for analyzing the impact of medication on hospital readmission risk among diabetic patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996dfe3",
   "metadata": {},
   "source": [
    "# **Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For Preprocessing\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# For Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# For Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score,roc_curve\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6926522",
   "metadata": {},
   "source": [
    "# Loading & Inspection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494a319",
   "metadata": {},
   "source": [
    "**Loading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetic_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4572483",
   "metadata": {},
   "source": [
    "**For column names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad62b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4698f78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first 5 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last 5 rows\n",
    "print(df.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa68a3c",
   "metadata": {},
   "source": [
    "**Shape of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e91951",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of the dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ebdec",
   "metadata": {},
   "source": [
    "**Dataset Info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check data types and non-null counts\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638100b",
   "metadata": {},
   "source": [
    "**Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Describe numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6a64cf",
   "metadata": {},
   "source": [
    " **Checking for Missing or Unknown Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec69674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '?' with NaN\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Check missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf1992",
   "metadata": {},
   "source": [
    "**Droping Irrelevant or Highly Missing Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary columns\n",
    "df.drop(['encounter_id', 'patient_nbr', 'weight', 'payer_code', 'medical_specialty'], axis=1, inplace=True)\n",
    "print(\"Shape after dropping columns:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63682ddd",
   "metadata": {},
   "source": [
    "**For Duplicate Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cb1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count duplicate rows\n",
    "print(\"Duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2cbce",
   "metadata": {},
   "source": [
    "**Drop Rows with Any Remaining Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff34c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# New shape after cleaning\n",
    "print(\"Shape after dropping missing data:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ec669",
   "metadata": {},
   "source": [
    " **Converting Categorical Features to Category Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b26ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='category').columns:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e47762",
   "metadata": {},
   "source": [
    "**Convert Target Variable to Binary Format**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['readmitted'] = df['readmitted'].replace({'>30': 0, '<30': 1, 'NO': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d1111",
   "metadata": {},
   "source": [
    "**Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6abdcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d41617",
   "metadata": {},
   "source": [
    "**Outlier Detection & Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ae0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "if 'readmitted' in numeric_cols:\n",
    "    numeric_cols.remove('readmitted')\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "print(\"Shape after outlier removal:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a112afc",
   "metadata": {},
   "source": [
    "**Define Features & Target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('readmitted', axis=1)\n",
    "y = df['readmitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57102cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf61c113",
   "metadata": {},
   "source": [
    "**Applying SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply SMOTE on training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449945f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_sm)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f3bdf",
   "metadata": {},
   "source": [
    "# Data Visualization (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7c6d2",
   "metadata": {},
   "source": [
    "**Visualizing Feature Distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE Class Distribution Plot\n",
    "y_sm_df = pd.DataFrame({'readmitted': y_train_sm})\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='readmitted', data=y_sm_df)\n",
    "plt.title(\"Readmission Class Distribution After SMOTE\")\n",
    "plt.xlabel(\"Readmitted\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c12de",
   "metadata": {},
   "source": [
    "**Correlation Heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5033097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Analysis after SMOTE\n",
    "X_sm_df = pd.DataFrame(X_train_sm, columns=X.columns)\n",
    "smote_df = X_sm_df.copy()\n",
    "smote_df['readmitted'] = y_train_sm\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(smote_df.corr(), cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap (After SMOTE)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8c0e5",
   "metadata": {},
   "source": [
    "**Medication vs Readmission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448ec8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_to_plot = ['insulin', 'metformin', 'glipizide', 'glyburide']\n",
    "for med in meds_to_plot:\n",
    "    plt.figure()\n",
    "    sns.countplot(x=med, hue='readmitted', data=df)\n",
    "    plt.title(f\"{med.capitalize()} vs Readmission\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f2d3de",
   "metadata": {},
   "source": [
    "**Cross-tab for insulin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45186cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crosstab for insulin vs readmission rate\n",
    "print(\"\\nReadmission Rate by Insulin Usage (%):\")\n",
    "print(pd.crosstab(df['insulin'], df['readmitted'], normalize='index') * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ff1b0",
   "metadata": {},
   "source": [
    "# Model Building & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c0280",
   "metadata": {},
   "source": [
    "**Defining Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b64d21",
   "metadata": {},
   "source": [
    "**Training & Evaluating**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    results[name] = {\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred),\n",
    "        'Classification Report': classification_report(y_test, y_pred, output_dict=True),\n",
    "        'ROC AUC': roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting Confusion Matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')\n",
    "    axes[i].set_title(f'{name} Confusion Matrix')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f934e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ploting ROC Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_score = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    auc = roc_auc_score(y_test, y_score)\n",
    "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {auc:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3859be85",
   "metadata": {},
   "source": [
    "**Model Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0c24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing Model Performance\n",
    "#Summary Table\n",
    "summary = pd.DataFrame({\n",
    "    name: {\n",
    "        'Accuracy': np.round(report['accuracy'], 3),\n",
    "        'Precision': np.round(report['1']['precision'], 3),\n",
    "        'Recall': np.round(report['1']['recall'], 3),\n",
    "        'F1-Score': np.round(report['1']['f1-score'], 3),\n",
    "        'ROC AUC': np.round(results[name]['ROC AUC'], 3)\n",
    "    }\n",
    "    for name, report in {k: v['Classification Report'] for k, v in results.items()}.items()\n",
    "}).T\n",
    "\n",
    "summary = summary.sort_values(by='Accuracy', ascending=False)\n",
    "print(\"\\nModel Performance Summary:\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0a7b3",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a60e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning using GridSearchCV for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train_sm)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best F1 Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601df212",
   "metadata": {},
   "source": [
    "**Evaluation of the best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "y_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\nBest Parameters:\", grid_search.best_params_)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb271df",
   "metadata": {},
   "source": [
    "**ROC Curve for Best Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c920a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"Optimized XGBoost (AUC = {roc_auc_score(y_test, y_proba):.2f})\", color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Optimized XGBoost\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57626f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Best Performing Model: Optimized XGBoost Classifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9e4ec",
   "metadata": {},
   "source": [
    "# Interpretation & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe013a",
   "metadata": {},
   "source": [
    "**Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bde3ee",
   "metadata": {},
   "source": [
    "After preprocessing the dataset by handling missing values, encoding categorical variables, balancing the target class using SMOTE, and scaling features, multiple classification models were built and evaluated. Among the models tested—Logistic Regression, Decision Tree, Random Forest, and XGBoost—**Optimised XGBoost** demonstrated the most balanced performance. While initial results showed high accuracy, this was mainly due to class imbalance. After hyperparameter tuning, XGBoost improved slightly in identifying readmitted patients, with a recall of 10% and a ROC AUC score of 0.55. This indicates that the model performs well in identifying patients who are not likely to be readmitted. Analysis also revealed that **insulin usage patterns and medication changes** were among the key factors influencing readmission likelihood. While the current model provides a strong baseline, improving the prediction of high-risk patients will require the inclusion of additional features such as patient compliance, time-based trends, or unstructured clinical data. This highlights the complexity of hospital readmission prediction and the importance of continuous model refinement for real-world healthcare decision support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8f796",
   "metadata": {},
   "source": [
    "**Insights**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfebde44",
   "metadata": {},
   "source": [
    "The key insight from this project is that high accuracy does not always reflect a model's true performance, especially when dealing with imbalanced healthcare data. While models like Logistic Regression and Random Forest achieved over 90% accuracy, they failed to identify positive readmission cases (readmitted = 1), resulting in zero recall and F1 score. This suggests a strong bias toward the majority class, which can be dangerous in healthcare applications where the minority class often represents high-risk patients. The optimized XGBoost model, although still limited, showed that boosting algorithms with proper tuning and class balancing techniques like SMOTE can slightly improve minority class detection. This emphasizes the importance of evaluating models using metrics like recall, F1 score, and AUC, rather than accuracy alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2068aed",
   "metadata": {},
   "source": [
    "**Visualize Feature Importance from XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff48b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_importance(best_model, max_num_features=10, importance_type='gain')  \n",
    "plt.title('Top 10 Important Features - XGBoost')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dab590",
   "metadata": {},
   "source": [
    "The model assigned high importance to number_inpatient, suggesting that patients with frequent prior hospitalizations are more likely to be readmitted.\n",
    "\n",
    "Medication changes, such as insulin_Up, were strong predictors, possibly reflecting worsening diabetes control before readmission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed43e879",
   "metadata": {},
   "source": [
    "**Save the best performing model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# best_model is your tuned XGBoost model from GridSearchCV\n",
    "joblib.dump(best_model, 'xgboost_best_model.pkl')\n",
    "print(\"Model saved as xgboost_best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d610f",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42118",
   "metadata": {},
   "source": [
    "This project focused on developing a machine learning model to predict 30-day hospital readmissions among diabetic patients using the diabetic_data.csv dataset. Comprehensive preprocessing steps were undertaken, including handling missing values, encoding categorical variables, outlier treatment, feature scaling, and balancing the imbalanced target variable using SMOTE. Several classification models were implemented and evaluated—Logistic Regression, Decision Tree, Random Forest, and XGBoost. Among these, the XGBoost classifier emerged as the best-performing model after hyperparameter tuning, achieving an overall accuracy of 85% and a modest improvement in recall and F1 score for the minority class. Despite this, the model's ability to accurately predict readmissions remained limited, reflecting the challenges of working with imbalanced healthcare data and limited feature granularity.\n",
    "\n",
    "The results underscore the potential of machine learning in supporting healthcare decision-making but also highlight important limitations. Medication data and administrative records alone may not be sufficient to capture the complex factors leading to readmission. To build more effective predictive systems, future work should explore the integration of richer clinical features—such as lab results, physician notes, and time-based health records—and advanced modeling approaches. Nonetheless, this project demonstrates a solid foundation in applying data science and machine learning techniques to a real-world healthcare problem, offering valuable insights for further research and practical deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693ab80",
   "metadata": {},
   "source": [
    "# Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18295c57",
   "metadata": {},
   "source": [
    "Despite rigorous tuning and balancing, the models consistently struggled to accurately identify patients who were readmitted within 30 days. This points to several limitations in the dataset and modeling approach. Firstly, the dataset primarily includes administrative and medication-related features, which may not capture the full clinical picture of a patient's health status or risk factors. Secondly, even after applying SMOTE to balance the dataset, the models were unable to generalize well to the test set in predicting the minority class. Additionally, the low recall and precision for the positive class suggest that the signal in the data may be too weak or insufficiently representative for effective classification. These limitations highlight the challenge of using structured tabular data alone for predictive healthcare tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77023d6",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3efdf",
   "metadata": {},
   "source": [
    "To improve predictive performance, especially for the minority class, future work should consider **enhancing the feature** set by incorporating more detailed clinical data such as lab results, vital signs, time-series trends, and physician notes from electronic health records (EHRs). Advanced machine learning approaches like **LightGBM, CatBoost, and deep learning-based models** can also be explored for better performance. Additionally, techniques like **cost-sensitive learning** and **custom loss functions** could be employed to penalize false negatives more heavily, thereby improving recall. Moreover, incorporating **threshold tuning** and **precision-recall curve analysis** could help fine-tune decision boundaries for better sensitivity. These future directions will help in building models that are not only accurate but also reliable and actionable in real-world healthcare settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f9e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
